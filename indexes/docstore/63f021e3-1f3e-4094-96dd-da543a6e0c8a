{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"doc_id": "63f021e3-1f3e-4094-96dd-da543a6e0c8a"}, "page_content": "3.4 Automating vs. augmenting users\n\nWhile the previous analyses reveal which tasks are seeing the most AI usage, they do not tell us how AI is being used for these tasks. A key distinction in the economics literature is between automation\u2014where technology substitutes for human labor\u2014and augmentation\u2014where technology complements and enhances human capabilities [Autor, 2015]. To understand which pattern is more prevalent, we used Clio to classify conversations into one of five different collaboration patterns6 grouped into automative vs. augmentative behaviors, listed in Table 1.\n\nBoth augmentative and automative collaboration behaviors are present in users\u2019 with Claude.ai interactions, with slightly more conversations being labeled as augmentative (57%) than automative (43%). That said, we note an important caveat that users might edit and adjust the response they receive from Claude outside the chat window, suggesting that the true proportion of augmentative conversations may be even higher. In addition, even automation of simple tasks can serve to enhance human capabilities when embedded within broader human-directed workflows.\n\nTo better understand the distribution of tasks across each of these collaboration patterns, we consider how automative versus augmentative behaviors differ across different occupational tasks:\n\nAutomative behaviors A majority of the Directive conversations consisted of writing and other content generation tasks. There was also a high percentage of Directive conversations in the business-relevant tasks such as \u201cDraft and optimize professional business email communications\u201d and schoolwork-related tasks such as \u201cSolve diverse geometry problems with calculations and proofs.\u201d The vast majority of the Feedback Loop conversations were related to coding and debugging, where the user repeatedly relayed the error they received back to the model.\n\n6We conduct human validation of these classifications. Details are included in Appendix C.\n\n9\n\nAutomative Behaviors Augmentative Behaviors AI directly executes tasks with minimal human AI enhances human capabilities through collab- involvement oration Directive: Complete task delegation with mini- Task Iteration: Collaborative refinement pro- mal interaction cess Illustrative Example: \u201cFormat this technical docu- Illustrative Example: \u201cLet\u2019s draft a marketing strategy mentation in Markdown\u201d for our new product. ... Good start, but can we add some concrete metrics?\u201d Feedback Loop: Task completion guided by Learning: Knowledge acquisition and under- environmental feedback standing Illustrative Example: \u201cHere\u2019s my Python script for Illustrative Example: \u201cCan you explain how neural data analysis \u2013 it\u2019s giving an IndexError. Can you networks work?\u201d help fix it? ... Now I\u2019m getting a different error...\u201d Validation: Work verification and improvement Illustrative Example: \u201cI\u2019ve written this SQL query to find duplicate customer records. Can you check if my logic is correct and suggest any improvements?\u201d\n\nTable 1: Taxonomy of Human-AI Collaboration Patterns. We classify conversations into five distinct patterns across two broad categories based on how people integrate AI into their workflow.\n\nAugmentation Pigs HE Validation IE Toskiteration MBE Learning MM Feedback loop ME Directive Automation 27.8% 0 10% 20% 30% 40% 50% 60% Percentage of Conversations\n\nFigure 7: Distribution of automative behaviors (43%) where users delegate tasks to AI, and augmentative behaviors (57%) where users actively collaborate with AI. Patterns are categorized into five modes of engagement; automative modes include Directive and Feedback Loop, while augmentative modes are comprised of Task Iteration, Learning, and Validation.\n\nAugmentative behaviors Task Iteration conversations often involved front-end development (tasks such as \"Assist with web development tasks and UI improvements\" and \"Create and modify landing pages and key website components\") as well as professional communication tasks (for example, \"Optimize resumes, cover letters, and job applications\" and \"Assist with professional and academic writing and communication\"). The highest percentage of Learning conversations occurs in general education tasks such as \u201cExplain and analyze martial law implementation and impacts,\u201d \u201cOffer gastroenterology and digestive health advice,\u201d and \u201cAssist with microcontroller programming and embedded systems projects\u201d. Validation was the smallest category of conversations, and was nearly all concentrated to tasks discussing language translations.\n\n10\n\nMore common for Claude 3.5 Sonnet Develop and maintain software applications and websites Program and debug computer systems and machinery Design and maintain database systems for data management and analysis Grade student work and assess academic and behavioral progress Produce and perform in film, TV, theater, and music Conduct academic research and disseminate findings Manage book and document publishing processes Design and develop comprehensive educational curricula and materials More common for Claude 3 Opus ~10% \u201c5% 0% 5% 10% Percentage Point Difference in Task Distribution\n\nFigure 8: Comparative analysis of task usage patterns between Claude Sonnet 3.5 (New) and Claude Opus models, showing differential preferences in usage. Sonnet 3.5 (New) demonstrates more usage for coding and technical tasks, while Opus is more used for creative writing and educa- tional content development.", "type": "Document"}}