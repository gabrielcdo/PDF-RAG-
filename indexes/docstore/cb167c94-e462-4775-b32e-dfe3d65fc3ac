{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"doc_id": "cb167c94-e462-4775-b32e-dfe3d65fc3ac"}, "page_content": "B.4 Usage by Occupational Skills\n\nThe O*NET database contains 35 unique occupational skills which identify key abilities for different occupations [National Center for O*NET Development, 2025a].\n\nSimilar to our analyses on Automating vs. Augmenting Users and Usage by Model Type, we create a Clio facet which assigns conversations to the most relevant occupational skills exhibited by the model. Each conversation is assigned to all skills exhibited by the assistant within the conversation. Assignments to multiple skills are allowed. There is also an option to return None if none of the skills apply to the conversation. In our analyses, we filtered out these classifications as only 0.1% of conversations were labeled None. For each conversation, the order of skills are shuffled before querying for an assignment to avoid any biases due to ordering. We include the complete prompt in Appendix F.\n\nB.5 Automating vs. Augmenting Tasks\n\nTo understand the nature of users\u2019 interactions with Claude, we construct a Clio facet to identify the collaboration pattern present in each conversation. We include our complete prompt in Appendix F. We intersect this facet with the previously-mentioned Clio facet mapping from conversations to O*NET tasks. Thus, for each O*NET task, Clio provides an associated breakdown across collab- oration patterns. This allows us to conduct fine-grained analysis on the nature of augmentation vs. automation for individual tasks (and thus also for occupations).\n\nB.6 Usage by Model Type\n\nUsing Clio, we analyze the distribution of Claude.ai conversations across different model types and O*NET tasks. By combining model usage data with our O*NET task mappings, we examine how Claude 3.5 Sonnet (new) and Claude 3 Opus are utilized across various task categories. Our sample consisted of approximately 54% Claude 3.5 Sonnet (new) conversations and 46% Claude 3 Opus conversations.\n\nB.7 Validating the Composition of our Dataset\n\nA natural concern with analyzing conversations with an AI assistant like Claude is that usage might be dominated by personal queries, homework help, or casual interactions rather than genuine occupa- tional tasks. To validate that our analysis captures predominantly occupational tasks, we conducted a systematic analysis of conversation types in our dataset. Using Clio, we classified each conversation into one of four categories for three different dimensions: work (explicitly work, likely work, possibly work, non-work), coursework (explicitly coursework, likely coursework, possibly coursework, non- coursework), and personal use (explicitly personal, likely personal, possibly personal, non-personal). We then examined the composition of tasks within each category using Clio.\n\n20\n\nAfter applying our occupational task screening, we found that non-work conversations only comprise 23% of the dataset, and usage relating to coursework comprises only 5-10% of conversations, depending on the chosen level of confidence. Importantly, we found that the majority of these \"non-work\" interactions still mapped meaningfully to occupational tasks. For example, personal nutrition planning relates to dietitian tasks, automated trading strategy development connects to financial analyst tasks, and travel itinerary planning maps to travel agent tasks. These results give us increased confidence in the utility of our dataset for understanding patterns of AI usage across economic tasks, regardless of whether those tasks happen within a formal work context.", "type": "Document"}}